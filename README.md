# TypeScriptによるコーディングエージェント開発研修: 仕組みを学び、実装する

## 1. はじめに

**ようこそ！**

このリポジトリは、TypeScriptとNode.jsを用いてシンプルな**コーディングエージェント**をゼロから開発するプロセスを学ぶための研修教材です。大規模言語モデル（LLM）であるGoogle Gemini APIを活用し、ローカルのターミナル上で動作するエージェントを作成します。

**目的:**

*   コーディングエージェントの基本的な仕組みと設計思想を理解する。
*   LLMとプログラム（ツール）を連携させる具体的な方法を学ぶ。
*   TypeScript/Node.jsにおける非同期処理、ファイルシステム操作、プロセス実行、標準入出力の扱いを実践する。
*   LLMを利用したアプリケーション開発における注意点（プロンプト、セキュリティ、エラーハンドリング）を体験する。

**対象者:**

*   TypeScriptおよびNode.jsの基本的な知識があるエンジニア。
*   LLMを活用したアプリケーション開発に興味がある方。
*   AIエージェントの内部構造を理解したい方。

**完成するエージェント:**

*   ユーザーの指示（自然言語）に基づき、Gemini APIに思考させる。
*   Geminiが必要と判断したツール（ファイル一覧表示、読み書き、コマンド実行、質問）をXML形式で要求する。
*   要求されたツールをローカル環境で実行し、結果をGeminiにフィードバックする。
*   危険な操作（ファイル書き込み、コマンド実行）の前にユーザーに承認を求める。
*   一連の対話ループを経てタスク完了を目指す。

このプロジェクトを通して、AIエージェント開発の第一歩を踏み出しましょう！

## 2. エージェントの仕組み（コンセプト）

このコーディングエージェントは、以下のコアアイデアに基づいています。

*   **思考と行動の分離:** LLM（Gemini）は「何をすべきか」を考え、ツールを選択する**思考**を担当します。実際のファイル操作やコマンド実行といった**行動**は、LLMではなくローカルで実行されるTypeScriptの関数（**ツール**）が担当します。これにより、LLMの能力とローカル環境の実行能力を安全かつ効果的に組み合わせます。
*   **対話ループ:** エージェントは以下のループを繰り返してタスクを遂行します。
    1.  **ユーザー指示:** ユーザーがエージェントにタスクを指示します。
    2.  **LLM思考:** エージェントはユーザー指示とこれまでの履歴をLLMに送信し、次に実行すべきツールとそのパラメータを考えさせます。
    3.  **ツール選択:** LLMは、定義されたツールの中から一つをXML形式で応答します。
    4.  **ツール実行:** エージェントはLLMの応答をパースし、対応するローカルのツール関数を実行します。（危険なツールの場合、ここでユーザー承認を求めます）
    5.  **結果フィードバック:** ツール実行結果（成功/失敗、出力メッセージ）をLLMに送り返します。
    6.  **LLM再思考:** LLMはツール結果を受け取り、タスクの次のステップを考え、必要なら別のツールを選択します。タスク完了なら `<complete>` ツールを選択します。
*   **ツールベースアプローチ:** LLMに直接「`fs.writeFile(...)`を実行して」と指示するのではなく、「`<write_file>`ツールを使って」と指示します。これにより、実行可能な操作を明確に定義・制限でき、セキュリティと制御性を高めます。
*   **XML形式の利用:** LLMに構造化された指示（ツール名とパラメータ）を出力させる方法として、XMLを採用しました。LLMは自然言語だけでなく、特定のフォーマットに従ったテキスト生成も得意です。XMLは多くの言語でパースしやすく、今回の目的には十分です。
    *   **補足:** Google Geminiには、よりモダンで堅牢な**Function Calling (Tool Calling)** 機能があります。これはJSONスキーマでツールを定義し、LLMが実行すべき関数名と引数をJSON形式で返す仕組みです。本格的な開発ではFunction Callingの利用が推奨されますが、本研修ではエージェントの基本的な仕組みを理解するため、よりシンプルなXMLベースのアプローチを採用しています。

## 3. 必要なもの

*   **Node.js:** v18以上推奨 ([公式サイト](https://nodejs.org/))
*   **npm** または **yarn:** Node.jsに付属
*   **TypeScript:** プロジェクトローカルにインストールします (`npm install typescript --save-dev`)
*   **Google Gemini APIキー:**
    *   [Google AI Studio](https://aistudio.google.com/) にアクセスし、APIキーを生成してください。
    *   **注意:** APIキーは機密情報です。絶対に公開しないでください。
*   **テキストエディタ / IDE:** Visual Studio Code推奨

## 4. セットアップ手順

1.  **リポジトリのクローン (またはコードのダウンロード):**
    ```bash
    git clone <リポジトリURL> # もしあれば
    cd <プロジェクトディレクトリ>
    ```
    または、提供されたソースコード (`src` フォルダ、`package.json`, `tsconfig.json`) を適切なディレクトリ構造で配置します。

2.  **依存関係のインストール:** プロジェクトのルートディレクトリで以下を実行します。
    ```bash
    npm install
    ```
    または
    ```bash
    yarn install
    ```

3.  **環境変数の設定:** プロジェクトのルートディレクトリに `.env` ファイルを作成し、以下のようにGemini APIキーを設定します。
    ```plaintext
    # .env
    GEMINI_API_KEY="YOUR_API_KEY_HERE"
    ```
    `YOUR_API_KEY_HERE` を実際に取得したAPIキーに置き換えてください。
    **重要:** `.gitignore` ファイルを作成し、`.env` や `node_modules`, `dist` を含めて、機密情報や生成物がGit管理されないようにしてください。
    ```plaintext
    # .gitignore
    node_modules
    dist
    .env
    ```

4.  **TypeScriptのコンパイル:** 以下のコマンドでTypeScriptコードをJavaScriptにコンパイルします。
    ```bash
    npx tsc
    ```
    これにより、`tsconfig.json` の設定 (`outDir: "./dist"`) に従って `dist` ディレクトリが作成され、その中にコンパイルされた `.js` ファイルが出力されます。

## 5. コード解説

プロジェクトの主要なファイルとその役割を見ていきましょう。

### 5.1. `src/types.ts`

アプリケーション全体で使用される型定義を集約しています。TypeScriptの利点を活かし、コードの可読性と安全性を高める上で重要です。

*   **ツールパラメータ:** 各ツール (`list_file`, `writeFile` など) が受け取るパラメータの型を `interface` で定義しています (`ListFileParams`, `WriteFileParams` など)。
*   **ツール応答:** すべてのツールが返す共通の応答形式 (`ToolResponse`) を定義しています。成功フラグ (`success`) とメッセージ (`message`) を持ちます。
*   **その他:** ツール関数のシグネチャ (`ToolFunction`) やパース結果の型 (`ParsedToolParams`) など、コード内で型安全性を保つための定義が含まれます。

### 5.2. `src/tools.ts`

エージェントの「手足」となる具体的な操作（ツール）を実装したファイルです。LLMから指示されたタスクを実際にローカル環境で実行します。

*   **Node.js 標準APIの活用:**
    *   `fs/promises`: ファイルシステムの非同期操作（読み書き、ディレクトリ作成など）に使用。
    *   `path`: プラットフォームに依存しないファイルパスの操作（結合、ディレクトリ名取得など）に使用。
    *   `child_process.exec`: シェルコマンドの実行に使用。`promisify` を使って Promise ベースで扱えるようにしています。
    *   `readline/promises`: ターミナルでのユーザーとの対話（質問、承認確認）に使用。
*   **非同期処理:** ほとんどのツールはファイルI/Oやプロセス実行を伴うため、`async/await` を用いた非同期関数として実装されています。これにより、処理の完了を待ち合わせつつ、コードの可読性を保っています。
*   **ツール実装:**
    *   `listFile`: 指定されたディレクトリの内容を一覧表示します。再帰的な探索も可能です。
    *   `readFile`: 指定されたファイルの内容を読み取ります。
    *   `writeFile`: 指定されたパスに内容を書き込みます。**ユーザー承認が必要です。**
    *   `askQuestion`: LLMがユーザーに追加情報を求めたい場合に使用します。
    *   `executeCommand`: 指定されたシェルコマンドを実行します。**ユーザー承認が必要です。**
    *   `complete`: LLMがタスク完了と判断した場合に呼び出されます。
*   **セキュリティ考慮 (`askForUserApproval`):**
    *   `writeFile` と `executeCommand` は潜在的に危険な操作であるため、実行前に必ず `askForUserApproval` 関数を呼び出してターミナルでユーザーの承認 (`y/n`) を求めます。承認されない限り、実際の操作は行われません。
    *   `readFile`, `writeFile`, `listFile` では、簡単なパストラバーサル対策 (`params.path.includes('..')`) も含まれていますが、実際のアプリケーションではより堅牢な検証が必要です。
*   **`readline` インターフェースの管理:** ユーザーとの対話に必要な `readline.Interface` は、グローバルに保持せず、`main.ts` で生成されたインスタンスを引数として受け取る設計になっています。これにより、インスタンスのライフサイクル管理が容易になり、意図しないクローズや競合を防ぎます。

### 5.3. `src/parser.ts`

LLMからの応答（XML形式のツール呼び出し）を解釈し、対応するツール関数を実行する役割を担います。

*   **LLM出力の揺らぎへの対処:** Gemini（や他のLLM）は、指示されたフォーマット（今回はXML）の他に、説明文やマークダウンのコードブロック記法 (` ```xml ... ``` `) を付加して応答することがあります。そのままではXMLパーサーがエラーを起こすため、`parseAndExecuteTool` 関数の冒頭で `trim()` や `replace()` を使ってこれらの余計な文字列を除去する**前処理**を行っています。これはLLMアプリケーション開発ではよく遭遇する課題の一つです。
*   **XMLパース:** `xml2js` ライブラリの `parseStringPromise` を使用して、クリーンナップされたXML文字列をJavaScriptオブジェクトに変換します。
*   **ツールディスパッチ:** パースされたXMLのルート要素名（ツール名）に基づき、`switch` 文を使って対応する `src/tools.ts` 内の関数を呼び出します。この際、ユーザー対話が必要なツール (`writeFile`, `askQuestion`, `executeCommand`) には、引数で受け取った `readline.Interface` を渡します。

### 5.4. `src/main.ts`

エージェント全体の動作を制御するメインファイルです。ユーザーとの対話、LLMとの通信、ツール実行のオーケストレーションを行います。

*   **初期化:**
    *   `dotenv` を使って `.env` ファイルから環境変数 (APIキー) を読み込みます。
    *   `@google/generative-ai` を使って Gemini API クライアント (`GoogleGenerativeAI`, `GenerativeModel`) を初期化します。安全性設定 (`safetySettings`) もここで行います。
    *   ユーザー対話用の `readline.Interface` を一つ生成します。
*   **システムプロンプト:** エージェントの役割、利用可能なツールとそのXML形式、守るべきルールなどを定義した長文のプロンプトです。`model.startChat()` の `systemInstruction` としてLLMに与えることで、エージェントとして振る舞うように指示します。プロンプトの内容がエージェントの性能を大きく左右します。
*   **メインループ (`while` ループ):**
    1.  現在のメッセージ (`messageToSend`) を `chat.sendMessage()` でGeminiに送信します。`chat` オブジェクトは内部で会話履歴を管理してくれます。
    2.  Geminiからの応答 (`assistantResponseText`) を受け取ります。（空でないか、安全性ブロックがないかなどをチェックします）
    3.  `parseAndExecuteTool` 関数を呼び出し、応答をパースして適切なツールを実行させます（`rl` インターフェースを渡します）。
    4.  ツールの実行結果 (`toolResponse`) を整形し、次のループでGeminiに送る `messageToSend` を準備します。
    5.  `complete` ツールが実行された場合、または最大ターン数に達した場合、ループを終了します。
*   **`readline` のライフサイクル管理:** `try...finally` ブロックを使用し、プログラムが正常終了した場合も、エラーで途中終了した場合も、必ず最後に `rl.close()` を呼び出して `readline` インターフェースを正しく閉じるようにしています。これにより、プロセスがハングアップするのを防ぎます。
*   **エラーハンドリング:**
    *   `try...catch` を使って、API通信エラー、パースエラー、ツール実行エラーなどを捕捉します。
    *   Geminiの応答が空だったり、安全性設定でブロックされた場合の処理分岐も含まれます。
    *   `process.on('unhandledRejection', ...)` を設定し、捕捉されなかった非同期処理のエラー（Promise rejection）を検知してログに出力するようにしています。

## 6. 実行方法

1.  **コンパイル (必須):** TypeScriptコードをJavaScriptに変換します。
    ```bash
    npx tsc
    ```
2.  **実行:** コンパイルされたコードを実行します。
    ```bash
    node dist/main.js
    ```
3.  **対話:**
    *   `Task:` と表示されたら、エージェントに実行させたいタスクを自然言語で入力します。
        *   例: `カレントディレクトリに "hello.txt" というファイルを作り、"Hello from Agent!" と書き込んでください`
        *   例: `src ディレクトリの中身を一覧表示して`
        *   例: `npm run build コマンドを実行して`
    *   エージェントがファイル書き込みやコマンド実行を試みる場合、`[y/n]:` というプロンプトが表示されるので、`y` (承認) または `n` (拒否) を入力して Enter キーを押します。
    *   エージェントはLLMとの対話を繰り返し、タスク完了を目指します。`<complete>` ツールが実行されるか、最大ターン数に達すると終了します。

## 7. 学びのポイント（まとめ）

この研修を通して、以下の点を実践的に学ぶことができました。

*   **エージェント思考:** LLMを知能（思考）とし、外部ツールを身体（行動）とする基本的なエージェントアーキテクチャを実装しました。
*   **プロンプトエンジニアリング:** システムプロンプトがいかにLLMの振る舞いを規定するか、ツールの定義や制約をどう伝えるかを学びました。
*   **LLMとの連携:** 自然言語だけでなく、XMLのような構造化データを用いてLLMと情報をやり取りする方法、そしてLLMの出力の揺らぎ（マークダウンなど）に対処する必要性を理解しました。
*   **Node.jsシステム操作:** ファイルシステム (`fs`)、子プロセス (`child_process`)、標準入出力 (`readline`) といったNode.jsのコア機能を活用してローカル環境を操作しました。
*   **非同期処理:** Node.jsにおける非同期処理の重要性と、`async/await` や `Promise` を使った実践的なコーディングを経験しました。
*   **セキュリティ意識:** LLMエージェントがローカル環境を操作する際の潜在的なリスク（意図しないファイル変更やコマンド実行）と、ユーザー承認などの基本的な対策の重要性を学びました。

## 8. 発展課題（Next Steps）

このシンプルなエージェントをベースに、さらに機能拡張や改善を行うことができます。

*   **Gemini Function Callingへの移行:** XMLパース処理をなくし、より堅牢で推奨される方法に移行してみましょう。[`@google/generative-ai` のドキュメント](https://ai.google.dev/docs/function_calling) を参照してください。
*   **ツールの追加:**
    *   Webブラウジングツール（例: `axios` や `node-fetch` でURLの内容を取得する）
    *   より高度なファイル操作ツール（移動、削除、検索など）
    *   簡単なデータベース操作ツール（例: SQLite）
    *   外部API連携ツール（天気予報、株価情報など）
*   **状態管理の強化:** 複数のステップにまたがる複雑なタスク（例: Gitリポジトリの操作）に対応するため、エージェントの内部状態（カレントディレクトリ、開いているファイルなど）を保持・管理する仕組みを導入します。
*   **エラーハンドリングの強化:**
    *   特定のエラーに対するリトライ機構の実装。
    *   LLMが不正なツール形式を返した場合のフォールバック処理。
    *   ユーザーへのより分かりやすいエラーメッセージ表示。
*   **ロギング・デバッグ機能:** 各ステップでのLLMとの詳細なやり取り（プロンプト、応答、ツール実行結果）をファイルに記録するなど、デバッグを容易にする仕組みを追加します。
*   **テストコード:** `jest` などのテストフレームワークを使って、各ツールの単体テストや、主要なシナリオの結合テストを作成します。
*   **UIの改善:**
    *   `inquirer.js` などのライブラリを使って、よりインタラクティブなCLIインターフェースを作成します。
    *   Webフレームワーク (Express, React, Vueなど) を使って、WebブラウザベースのUIを作成します。

## 9. 貢献

もしバグを見つけたり、改善提案がある場合は、お気軽にIssueを立てたり、Pull Requestを送ってください（もしこのプロジェクトがGitHubなどで公開されている場合）。

---

この研修教材が、あなたのAIエージェント開発への理解を深める一助となれば幸いです。Happy Coding! 🚀